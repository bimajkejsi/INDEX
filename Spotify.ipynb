{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the Spotify Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "# Load the required libraries\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "# rdflib knows about some namespaces, like FOAF\n",
    "from rdflib.namespace import FOAF, XSD\n",
    "# CHECK DATE \n",
    "import datetime\n",
    "from rdflib.namespace import OWL, RDFS\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\wamp64\\www/INDEX/spotify/dataset/rdf/\n"
     ]
    }
   ],
   "source": [
    "# parameters and URLs\n",
    "path = str(Path(os.path.abspath(os.getcwd())).parent.absolute())\n",
    "\n",
    "# #spotify codes\n",
    "\n",
    "spotify = os.path.join(path, 'INDEX', 'spotify', 'dataset', 'chart.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # saving folder\n",
    "savePath =  path + '/INDEX/spotify/dataset/rdf/'\n",
    "print (savePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the country and the spotify ontology namespaces not known by RDFlib\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "SP = Namespace(\"http://www.dei.unipd.it/GraphDatabases/SpotifyOntology#\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country_name  country_id\n",
      "0         Argentina           1\n",
      "201       Australia           2\n",
      "313          Brazil           3\n",
      "402         Austria           4\n",
      "525         Belgium           5\n",
      "...             ...         ...\n",
      "68439       Vietnam          60\n",
      "68791         Egypt          61\n",
      "109596        India          62\n",
      "110196       Israel          63\n",
      "111912      Morocco          64\n",
      "\n",
      "[64 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a pandas DataFrame\n",
    "spotify_data = pd.read_csv(spotify)\n",
    "# Extract unique regions as countries\n",
    "Countries = spotify_data[['region']].drop_duplicates().rename(columns={'region': 'country_name'})\n",
    "\n",
    "# Add a unique country_id\n",
    "Countries['country_id'] = range(1, len(Countries) + 1)\n",
    "\n",
    "print(Countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"sp\", SP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 6.93 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the country dataframe\n",
    "for index, row in Countries.iterrows():\n",
    "    # Create the node to add to the Graph\n",
    "    # the node has the namespace + the league id as URI\n",
    "    idU = \"country\"+str(index)\n",
    "    Country = URIRef(SP[idU])\n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Country, RDF.type, SP.Country))\n",
    "    g.add((Country, SP['region'], Literal(row['country_name'], datatype=XSD.string)))    \n",
    "# Correcting the visualization with the provided namespace SP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 14.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "# with open(savePath + 'leagues.ttl', 'w') as file:\n",
    "with open(savePath + 'country.ttl', 'w', encoding='utf-8') as file:\n",
    "    file.write(g.serialize(format='turtle'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "\n",
    "# clubs = pd.read_csv(spotify, sep=',', index_col='Arist_id')\n",
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"so\", SP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique artists from the dataset\n",
    "unique_artists = spotify_data['artist'].reset_index(drop=True)\n",
    "\n",
    "# Add a unique artist_id to each artist\n",
    "unique_artists = unique_artists.reset_index().rename(columns={'index': 'artist_id'})\n",
    "\n",
    "# Iterate over the unique artists DataFrame\n",
    "for _, row in unique_artists.iterrows():\n",
    "    # Create the URI for the Artist using the unique artist_id\n",
    "    Artist = URIRef(SP[f\"artist{row['artist_id']}\"])  # Artist node URI\n",
    "\n",
    "    # Add the Artist as a class in the graph\n",
    "    g.add((Artist, RDF.type, SP.Artist))  # Declaring it as an Artist\n",
    "    g.add((Artist, SP['name'], Literal(row['artist'], datatype=XSD.string)))  # Adding the artist's name\n",
    "    g.add((Artist, SP['artist_id'], Literal(row['artist_id'], datatype=XSD.integer)))  # Adding the artist's ID\n",
    "   # Create a FOAF Person node\n",
    "    Person = URIRef(FOAF[\"Person\"])\n",
    "    g.add((Artist, SP['isMemberOf'], Person))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 10.8 s\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'artist.ttl', 'w', encoding='utf-8') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "\n",
    "# clubs = pd.read_csv(spotify, sep=',', index_col='Arist_id')\n",
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"so\", SP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RDF graph\n",
    "Chart = SP.Chart\n",
    "Top200 = SP.Top200\n",
    "Viral50 = SP.Viral50\n",
    "# Add the Chart class and its subclasses\n",
    "g.add((Chart, RDF.type, OWL.Class))\n",
    "g.add((Top200, RDF.type, OWL.Class))\n",
    "g.add((Viral50, RDF.type, OWL.Class))\n",
    "\n",
    "# Subclass relationships\n",
    "g.add((Top200, RDFS.subClassOf, Chart))\n",
    "g.add((Viral50, RDFS.subClassOf, Chart))\n",
    "\n",
    "# Add properties\n",
    "associatedWith = SP.associatedWith\n",
    "publishedIn = SP.publishedIn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RankedRecorded "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
