{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the Spotify Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "# Load the required libraries\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "# rdflib knows about some namespaces, like FOAF\n",
    "from rdflib.namespace import FOAF, XSD\n",
    "# CHECK DATE \n",
    "import datetime\n",
    "from rdflib.namespace import OWL, RDFS\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters and URLs\n",
    "path = str(Path(os.path.abspath(os.getcwd())).parent.absolute())\n",
    "\n",
    "# #spotify codes\n",
    "spotify = os.path.join(path, 'INDEX', 'spotify', 'dataset', 'chart.csv')\n",
    "\n",
    "# saving folder\n",
    "savePath =  path + '/INDEX/spotify/dataset/rdf/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the country and the spotify ontology namespaces not known by RDFlib\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "SP = Namespace(\"http://www.dei.unipd.it/GraphDatabases/SpotifyOntology#\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a pandas DataFrame\n",
    "spotify_data = pd.read_csv(spotify)\n",
    "# Extract unique regions as countries\n",
    "Countries = spotify_data[['region']].drop_duplicates().rename(columns={'region': 'country_name'})\n",
    "\n",
    "# Add a unique country_id\n",
    "Countries['country_id'] = range(1, len(Countries) + 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"sp\", SP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 13.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "# Dictionary to store unique country URIs\n",
    "country_mapping = {}\n",
    "\n",
    "# Process unique regions (countries)\n",
    "for region in spotify_data['region'].unique():\n",
    "    if region not in country_mapping:\n",
    "        # Create a unique URI for the country\n",
    "        country_id = f\"country{len(country_mapping) + 1}\"  # ID starts from 1\n",
    "        Country = URIRef(CNS[country_id])\n",
    "        country_mapping[region] = Country  # Add region to the mapping\n",
    "        \n",
    "        # Add triples\n",
    "        g.add((Country, RDF.type, SP.Country))\n",
    "        g.add((Country, SP['region'], Literal(region, datatype=XSD.string)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 7.96 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "# with open(savePath + 'leagues.ttl', 'w') as file:\n",
    "with open(savePath + 'country.ttl', 'w', encoding='utf-8') as file:\n",
    "    file.write(g.serialize(format='turtle'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "\n",
    "\n",
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"so\", SP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique artists from the dataset\n",
    "# Process the artists\n",
    "artists = spotify_data['artist'].unique()  # Get unique artists\n",
    "\n",
    "for index, artist in enumerate(artists):\n",
    "    # Create a unique URI for each artist\n",
    "    artist_id = f\"artist{index + 1}\"  # ID starts from 1\n",
    "    Artist = URIRef(SP[artist_id])\n",
    "    \n",
    "    # Add triples for the artist\n",
    "    g.add((Artist, RDF.type, SP.Artist))  # Declare as an Artist\n",
    "    g.add((Artist, FOAF.name, Literal(artist, datatype=XSD.string)))  # Add name\n",
    "\n",
    "    # Link Artist to Person using isMemberOf\n",
    "    Person = URIRef(SP[f\"person{index + 1}\"])  # Unique URI for Person\n",
    "    g.add((Artist, SP['isMemberOf'], Person))\n",
    "    g.add((Person, RDF.type, FOAF.Person))  # Declare as a Person\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 219 ms\n",
      "Wall time: 998 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'artist.ttl', 'w', encoding='utf-8') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RDF graph\n",
    "g = Graph()\n",
    "g.bind(\"spotify\", SP)\n",
    "g.bind(\"countries\", CNS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map artist names to URIs\n",
    "artist_mapping = {}\n",
    "\n",
    "# Process the songs\n",
    "for index, row in spotify_data.iterrows():\n",
    "    # Create a unique URI for each song\n",
    "    song_id = f\"song{index + 1}\"  # ID starts from 1\n",
    "    Song = URIRef(SP[song_id])\n",
    "    \n",
    "    # Add triples for the song\n",
    "    g.add((Song, RDF.type, SP.Song))  # Declare as a Song\n",
    "    g.add((Song, SP['songUrl'], Literal(row['url'], datatype=XSD.string)))  # Add song URL\n",
    "    \n",
    "    # Add the relationship \"popularIn\" (Song → Country)\n",
    "    country_id = f\"country{index + 1}\"  # Assume region corresponds to the processed Country ID\n",
    "    Country = URIRef(CNS[country_id])\n",
    "    g.add((Song, SP['popularIn'], Country))  # Link song to country\n",
    "    \n",
    "    # Add the relationship \"PerformedBy\" (Song → Artist)\n",
    "    artist_name = row['artist']\n",
    "    \n",
    "    # Check if the artist already exists in the mapping\n",
    "    if artist_name not in artist_mapping:\n",
    "        # Create a new URI for the artist\n",
    "        artist_id = f\"artist{len(artist_mapping) + 1}\"\n",
    "        Artist = URIRef(SP[artist_id])\n",
    "        \n",
    "        # Add artist to the mapping\n",
    "        artist_mapping[artist_name] = Artist\n",
    "        \n",
    "        # Add triples for the artist\n",
    "        g.add((Artist, RDF.type, SP.Artist))\n",
    "        g.add((Artist, SP['name'], Literal(artist_name, datatype=XSD.string)))\n",
    "        g.add((Artist, SP['isMemberOf'], URIRef(\"http://xmlns.com/foaf/0.1/Person\")))  # Link to FOAF Person\n",
    "    \n",
    "    # Link the song to the artist\n",
    "    g.add((Song, SP['PerformedBy'], artist_mapping[artist_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 15.8 s\n",
      "Wall time: 27.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'song.ttl', 'w', encoding='utf-8') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RDF graph\n",
    "g = Graph()\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"spotify\", SP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Chart and its subclasses\n",
    "Chart = URIRef(SP.Chart)\n",
    "Top200 = URIRef(SP.Top200)\n",
    "Viral50 = URIRef(SP.Viral50)\n",
    "\n",
    "# Add triples for Chart and its subclasses\n",
    "g.add((Chart, RDF.type, RDFS.Class))\n",
    "g.add((Top200, RDF.type, RDFS.Class))\n",
    "g.add((Viral50, RDF.type, RDFS.Class))\n",
    "g.add((Top200, RDFS.subClassOf, Chart))\n",
    "g.add((Viral50, RDFS.subClassOf, Chart))\n",
    "\n",
    "\n",
    "\n",
    "# Add publishedIn relationships for Charts\n",
    "for chart_type in ['Top200', 'Viral50']:\n",
    "    chart_instance = URIRef(SP[chart_type])\n",
    "    for region in spotify_data['region'].unique():\n",
    "        # Link each chart type to the existing country URIs (defined in countries.ttl)\n",
    "        country_id = f\"country{spotify_data['region'].unique().tolist().index(region) + 1}\"\n",
    "        Country = URIRef(CNS[country_id])  # Reuse existing country URIs\n",
    "        g.add((chart_instance, SP['publishedIn'], Country))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- saving serialization ---\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 2.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'chart.ttl', 'w', encoding='utf-8') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RankedRecorded "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
